{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp00+491gEyVmwTkiWMYif",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/serega-sergei/SpringBoard_ML/blob/main/Siarhei_Siryk_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mini Project: Build a Machine Learning Model**\n",
        "\n",
        "Predict Total Fare on the NYC Taxi Dataset\n",
        "Welcome to the NYC Taxi Fare Prediction project! In this Colab, we will continue using the NYC Taxi Dataset to predict the fare amount for taxi rides using a subset of available features. We will go through three main stages: building a baseline model, creating a full model, and performing hyperparameter tuning to enhance our predictions.\n",
        "\n",
        "Now that you've completed exploratory data analysis on this dataset you should have a good understanding of the feature space.\n",
        "\n",
        "# **Project Objectives**\n",
        "The primary objectives of this project are as follows:\n",
        "\n",
        "Baseline Model: We will start by building a simple baseline model to establish a benchmark for our predictions. This model will serve as a starting point to compare the performance of our subsequent models.\n",
        "\n",
        "Full Model: Next, we will develop a more comprehensive model that leverages machine learning techniques to improve prediction accuracy. We will use Scikit-Learn's model pipeline to build a framework that enables rapid experimentation.\n",
        "\n",
        "Hyperparameter Tuning: Lastly, we will optimize our full model by fine-tuning its hyperparameters. By systematically adjusting the parameters that control model behavior, we aim to achieve the best possible performance for our prediction task.\n",
        "\n",
        "https://github.com/springboard-curriculum/guild-mle-projects/blob/main/Student_MLE_MiniProject_ML.ipynb"
      ],
      "metadata": {
        "id": "AM_Qo_51SMgl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "BPjRYDgDSJAo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a pandas DataFrame (from https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)\n",
        "# url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\"\n",
        "\n",
        "# df = pd.read_parquet(url)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "file_name = list(uploaded.keys())[0]  # Get the name of the uploaded file\n",
        "df = pd.read_parquet(file_name)\n",
        "\n",
        "# Check the first few rows of the dataframe\n",
        "df.head()"
      ],
      "metadata": {
        "id": "UIXKvBamS17w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "d148e424-334d-40be-b1f9-f5876b9365f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1dbb0693-3595-4995-9d54-c6ceee0a4975\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1dbb0693-3595-4995-9d54-c6ceee0a4975\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the dataset\n",
        "print(df.head(5))"
      ],
      "metadata": {
        "id": "788phvomTCb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values.\n",
        "df_clean = df.dropna()"
      ],
      "metadata": {
        "id": "w9G5x-5sTK66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new feature, 'trip_duration'.\n",
        "pickup_col = 'tpep_pickup_datetime'\n",
        "dropoff_col = 'tpep_dropoff_datetime'\n",
        "\n",
        "df_clean.loc[:, pickup_col] = pd.to_datetime(df_clean[pickup_col])\n",
        "df_clean.loc[:, dropoff_col] = pd.to_datetime(df_clean[dropoff_col])\n",
        "\n",
        "df_clean.loc[:, 'trip_duration'] = (df_clean[dropoff_col] - df_clean[pickup_col]).dt.total_seconds()\n",
        "\n",
        "print(df_clean[[pickup_col, dropoff_col, 'trip_duration']].head())"
      ],
      "metadata": {
        "id": "Smdp9lESTX7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list called feature_col to store column names\n",
        "target_col = 'total_amount'\n",
        "feature_col = [col for col in df_clean.columns if col != target_col]\n",
        "\n",
        "print(feature_col)"
      ],
      "metadata": {
        "id": "yYG4-Nb2VamQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_clean[feature_col]\n",
        "y = df_clean['total_amount']\n",
        "\n",
        "# Split into train and test sets (e.g., 80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "m9KwVuKnVwhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a baseline for mean absolute error of total amount\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Define the target column\n",
        "target_col = 'total_amount'\n",
        "\n",
        "# Use the mean of the training target as the baseline prediction\n",
        "baseline_pred = y_train.mean()\n",
        "\n",
        "# Create an array of baseline predictions (same length as y_test)\n",
        "baseline_preds = [baseline_pred] * len(y_test)\n",
        "\n",
        "# Calculate the Mean Absolute Error\n",
        "baseline_mae = mean_absolute_error(y_test, baseline_preds)\n",
        "\n",
        "print(f\"Baseline MAE (predicting mean {target_col}): {baseline_mae:.2f}\")"
      ],
      "metadata": {
        "id": "776SROPjHtbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Scikit-Learn's ColumnTransformer to preprocess the categorical and\n",
        "# continuous features independently.\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "categorical_features = [\n",
        "    'VendorID', 'RatecodeID', 'store_and_fwd_flag',\n",
        "    'PULocationID', 'DOLocationID', 'payment_type'\n",
        "]\n",
        "\n",
        "numerical_features = [\n",
        "    'passenger_count', 'trip_distance', 'trip_duration', 'fare_amount',\n",
        "    'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
        "    'improvement_surcharge', 'congestion_surcharge', 'airport_fee'\n",
        "]\n",
        "\n",
        "# Define preprocessing steps\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "numerical_transformer = StandardScaler()\n",
        "\n",
        "# Combine into ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "GePz_EbFIr1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pipeline object containing the column transformations and regression\n",
        "# model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Train the pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Liner Regression MAE: {mae:.2f}\")"
      ],
      "metadata": {
        "id": "w4jeN9ZJI5dM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build random forest regressor model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# n_jobs=-1 - use all available cores\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "# will be using trip_duration instead due to TypeError: float() argument must be a string or a real number, not 'Timestamp'\n",
        "feature_col = [col for col in df_clean.columns if col != 'tpep_pickup_datetime' and col != 'tpep_dropoff_datetime']\n",
        "\n",
        "# Ensure store_and_fwd_flag is numeric\n",
        "df_clean['store_and_fwd_flag'] = df_clean['store_and_fwd_flag'].map({'N': 0, 'Y': 1})\n",
        "\n",
        "X = df_clean[feature_col]\n",
        "y = df_clean['total_amount']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "rf_y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "mae = mean_absolute_error(y_test, rf_y_pred)\n",
        "r2 = r2_score(y_test, rf_y_pred)\n",
        "\n",
        "print(f\"Random Forest MAE: {mae:.2f}\")\n",
        "print(f\"Random Forest R²: {r2:.2f}\")"
      ],
      "metadata": {
        "id": "rEe-yHNdMJI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters to tune.\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
        "    'max_depth': [10, 20, 30, None],  # Depth of the tree\n",
        "    'min_samples_split': [2, 5, 10]  # Minimum samples required to split an internal node\n",
        "}"
      ],
      "metadata": {
        "id": "L1VZDE0AUp_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform grid search to find the best hyperparameters. This could take a while.\n",
        "rf_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "# Step 3: Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "dxf2QiqYUvpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model and its parameters.\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best parameters found: {best_params}\")\n",
        "\n",
        "best_rf_model = RandomForestRegressor(n_estimators=best_params['n_estimators'],\n",
        "                                      max_depth=best_params['max_depth'],\n",
        "                                      min_samples_split=best_params['min_samples_split'],\n",
        "                                      random_state=42, n_jobs=-1)"
      ],
      "metadata": {
        "id": "st0QQoHrU5Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the best classifier on the training data.\n",
        "best_rf_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "LF7cPi_tVFbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Random Forest MAE: {mae:.2f}\")\n",
        "print(f\"Random Forest R²: {r2:.2f}\")"
      ],
      "metadata": {
        "id": "fQcKDA5AVN_f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}